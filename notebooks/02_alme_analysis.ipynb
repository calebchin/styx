{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALME Optimizer Analysis\n",
    "\n",
    "This notebook analyzes the performance of the Adaptive Local Minima Escape (ALME) optimizer compared to baseline optimizers (SGD, Adam, AdamW).\n",
    "\n",
    "## Overview\n",
    "\n",
    "ALME combines Adam-based gradient descent with a local minima escape mechanism:\n",
    "1. Detects stagnation via gradient norm and loss plateaus\n",
    "2. Samples perturbed weight candidates\n",
    "3. Evaluates candidates with mini-optimization runs\n",
    "4. Continues from the best candidate\n",
    "\n",
    "We'll test ALME on:\n",
    "- MNIST classification\n",
    "- Smooth vs jagged loss landscapes\n",
    "- Synthetic optimization problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "from styx.datasets.loaders import get_mnist_loaders\n",
    "from styx.models.simple_nets import MLP\n",
    "from styx.optimizers import ALME\n",
    "from styx.visualization.plots import (\n",
    "    plot_escape_events,\n",
    "    plot_optimizer_comparison_detailed,\n",
    "    plot_population_diversity,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Experiment Results\n",
    "\n",
    "First, let's load the results from the benchmark experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"../experiments/results\")\n",
    "\n",
    "# Load baseline results\n",
    "baseline_sgd = json.load(open(results_dir / \"baseline_sgd_results.json\"))\n",
    "baseline_adam = json.load(open(results_dir / \"baseline_adam_results.json\"))\n",
    "baseline_adamw = json.load(open(results_dir / \"baseline_adamw_results.json\"))\n",
    "\n",
    "# Load ALME results\n",
    "alme_shallow = json.load(open(results_dir / \"alme_mnist_shallow_results.json\"))\n",
    "alme_aggressive = json.load(open(results_dir / \"alme_mnist_aggressive_results.json\"))\n",
    "\n",
    "print(\"✓ Results loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare Optimizer Performance\n",
    "\n",
    "Let's create comprehensive comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results for comparison\n",
    "comparison_results = {\n",
    "    \"SGD\": baseline_sgd,\n",
    "    \"Adam\": baseline_adam,\n",
    "    \"AdamW\": baseline_adamw,\n",
    "    \"ALME (shallow)\": alme_shallow,\n",
    "    \"ALME (aggressive)\": alme_aggressive,\n",
    "}\n",
    "\n",
    "# Create detailed comparison plot\n",
    "plot_optimizer_comparison_detailed(\n",
    "    comparison_results,\n",
    "    save_path=\"../experiments/results/optimizer_comparison.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze ALME Escape Events\n",
    "\n",
    "Let's examine when and how ALME escapes local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot escape events for shallow ALME\n",
    "print(\"ALME (Shallow Configuration):\")\n",
    "plot_escape_events(\n",
    "    alme_shallow[\"val_loss_history\"],\n",
    "    alme_shallow[\"alme_stats\"],\n",
    "    save_path=\"../experiments/results/alme_shallow_escapes.png\",\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "final_stats = alme_shallow[\"final_alme_stats\"]\n",
    "print(f\"Total escapes: {final_stats['escape_count']}\")\n",
    "print(f\"Average escape distance: {final_stats['avg_escape_distance']:.6f}\")\n",
    "print(f\"Best validation loss: {final_stats['best_val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot escape events for aggressive ALME\n",
    "print(\"\\nALME (Aggressive Configuration):\")\n",
    "plot_escape_events(\n",
    "    alme_aggressive[\"val_loss_history\"],\n",
    "    alme_aggressive[\"alme_stats\"],\n",
    "    save_path=\"../experiments/results/alme_aggressive_escapes.png\",\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "final_stats = alme_aggressive[\"final_alme_stats\"]\n",
    "print(f\"Total escapes: {final_stats['escape_count']}\")\n",
    "print(f\"Average escape distance: {final_stats['avg_escape_distance']:.6f}\")\n",
    "print(f\"Best validation loss: {final_stats['best_val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Population Diversity Analysis\n",
    "\n",
    "Analyze how ALME explores the parameter space during escapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot population diversity for both configurations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_population_diversity(alme_shallow[\"alme_stats\"])\n",
    "axes[0].set_title(\"ALME Shallow - Population Diversity\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_population_diversity(alme_aggressive[\"alme_stats\"])\n",
    "axes[1].set_title(\"ALME Aggressive - Population Diversity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../experiments/results/population_diversity_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Performance Metrics\n",
    "\n",
    "Compare final performance metrics across all optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "\n",
    "for name, results in comparison_results.items():\n",
    "    row = {\n",
    "        \"Optimizer\": name,\n",
    "        \"Final Train Loss\": results[\"final_train_loss\"],\n",
    "        \"Final Val Loss\": results[\"final_val_loss\"],\n",
    "        \"Best Val Loss\": results[\"best_val_loss\"],\n",
    "        \"Final Train Acc\": results[\"train_accuracy_history\"][-1],\n",
    "        \"Final Val Acc\": results[\"val_accuracy_history\"][-1],\n",
    "    }\n",
    "    \n",
    "    if \"final_alme_stats\" in results:\n",
    "        row[\"Escape Count\"] = results[\"final_alme_stats\"][\"escape_count\"]\n",
    "        row[\"Avg Escape Dist\"] = results[\"final_alme_stats\"][\"avg_escape_distance\"]\n",
    "    else:\n",
    "        row[\"Escape Count\"] = \"-\"\n",
    "        row[\"Avg Escape Dist\"] = \"-\"\n",
    "    \n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nOptimizer Performance Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv(\"../experiments/results/optimizer_summary.csv\", index=False)\n",
    "print(\"\\n✓ Summary saved to optimizer_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Landscape Analysis\n",
    "\n",
    "If landscape analysis results are available, let's examine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_results_path = Path(\"../experiments/results/landscape/landscape_analysis_results.json\")\n",
    "\n",
    "if landscape_results_path.exists():\n",
    "    landscape_results = json.load(open(landscape_results_path))\n",
    "    \n",
    "    print(\"Landscape Analysis Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for landscape, optimizers in landscape_results.items():\n",
    "        print(f\"\\n{landscape}:\")\n",
    "        for opt_name, opt_results in optimizers.items():\n",
    "            if \"final_loss\" in opt_results:\n",
    "                print(f\"  {opt_name}: {opt_results['final_loss']:.6f}\")\n",
    "            elif \"final_val_loss\" in opt_results:\n",
    "                print(f\"  {opt_name}: Val Loss={opt_results['final_val_loss']:.4f}, \"\n",
    "                      f\"Val Acc={opt_results['final_val_accuracy']:.4f}\")\n",
    "else:\n",
    "    print(\"Landscape analysis results not found. Run landscape_analysis.py first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Curves Comparison\n",
    "\n",
    "Plot training and validation curves side by side for detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax = axes[0, 0]\n",
    "for name, results in comparison_results.items():\n",
    "    epochs = range(1, len(results[\"train_loss_history\"]) + 1)\n",
    "    ax.plot(epochs, results[\"train_loss_history\"], label=name, marker=\"o\", markersize=3)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Training Loss\")\n",
    "ax.set_title(\"Training Loss Comparison\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "ax = axes[0, 1]\n",
    "for name, results in comparison_results.items():\n",
    "    epochs = range(1, len(results[\"val_loss_history\"]) + 1)\n",
    "    ax.plot(epochs, results[\"val_loss_history\"], label=name, marker=\"s\", markersize=3)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Validation Loss\")\n",
    "ax.set_title(\"Validation Loss Comparison\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Training Accuracy\n",
    "ax = axes[1, 0]\n",
    "for name, results in comparison_results.items():\n",
    "    epochs = range(1, len(results[\"train_accuracy_history\"]) + 1)\n",
    "    ax.plot(epochs, results[\"train_accuracy_history\"], label=name, marker=\"o\", markersize=3)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Training Accuracy\")\n",
    "ax.set_title(\"Training Accuracy Comparison\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Validation Accuracy\n",
    "ax = axes[1, 1]\n",
    "for name, results in comparison_results.items():\n",
    "    epochs = range(1, len(results[\"val_accuracy_history\"]) + 1)\n",
    "    ax.plot(epochs, results[\"val_accuracy_history\"], label=name, marker=\"s\", markersize=3)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Validation Accuracy\")\n",
    "ax.set_title(\"Validation Accuracy Comparison\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../experiments/results/training_curves_detailed.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Insights and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Escape Mechanism Effectiveness**: Analyze whether ALME successfully escapes local minima and improves performance\n",
    "2. **Hyperparameter Sensitivity**: Compare shallow vs aggressive configurations\n",
    "3. **Computational Cost**: Consider the overhead of candidate sampling and evaluation\n",
    "4. **Landscape Dependence**: Examine performance on smooth vs jagged surfaces\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Test on more challenging datasets (CIFAR-10, Fashion-MNIST)\n",
    "- Experiment with different scale distributions\n",
    "- Tune stagnation detection parameters\n",
    "- Compare with other advanced optimizers (RAdam, Lookahead, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print key insights\n",
    "print(\"Key Performance Metrics:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, results in comparison_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Best Val Loss: {results['best_val_loss']:.4f}\")\n",
    "    print(f\"  Final Val Acc: {results['val_accuracy_history'][-1]:.4f}\")\n",
    "    \n",
    "    if \"final_alme_stats\" in results:\n",
    "        stats = results[\"final_alme_stats\"]\n",
    "        print(f\"  Total Escapes: {stats['escape_count']}\")\n",
    "        if stats['escape_count'] > 0:\n",
    "            print(f\"  Avg Escape Distance: {stats['avg_escape_distance']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
